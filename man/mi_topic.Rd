% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mi.R
\name{mi_topic}
\alias{mi_topic}
\title{Mutual information of words and documents in a topic}
\usage{
mi_topic(m, k, groups = NULL)
}
\arguments{
\item{m}{\code{mallet_model} object \emph{with sampling state loaded} via \code{\link{load_sampling_state}}}

\item{k}{topic number (calculations are only done for one topic at a time)}

\item{groups}{optional grouping factor for documents. If omitted, the MI over documents is calculated.}
}
\value{
a single value, giving the estimated mutual information.
}
\description{
Calculates the mutual information of words and documents within a given topic. This measures the degree to which the estimated distribution over words within the topic violates the assumption that it is independent of the distribution of words over documents.
}
\details{
The mutual information is given by

\deqn{
MI(W, D|K=k) = \sum_{w, d} p(w, d|k) \log\frac{p(w, d|k)}{p(w|k) p(d|k)}
}

In the limit of true independence, the fraction in the log is one and the MI 
is zero. In general, we can rewrite the sum as

\deqn{
\sum_d p(d|k) \sum_w p(w|d, k) \log\frac{p(w|d, k)}{p(w|k)}
}

which is \eqn{E_D(KL(W|d, W)}, the expected divergence of the conditional distribution from the marginal distribution. It can be shown with some algebra that

\deqn{
MI(W, D|k) = \sum_{w} p(w|k) IMI(w|k)
}

where the IMI is defined as specified in the Details for \code{\link{imi}}. This is the formula used for calculation here.

We can replace \eqn{D} with a grouping over documents and the formulas carry 
over without further change, now expressing the mutual information of those groupings and words within the topic.
}
\seealso{
\code{\link{imi}}, \code{\link{imi_check}}, \code{\link{mi_check}}
}

